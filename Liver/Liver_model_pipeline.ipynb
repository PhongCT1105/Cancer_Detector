{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/liver+normal.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataset/liver+normal.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m shuffle(df, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m), df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Study\\CS_539\\Cancer_Detector\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Study\\CS_539\\Cancer_Detector\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Study\\CS_539\\Cancer_Detector\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Study\\CS_539\\Cancer_Detector\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Study\\CS_539\\Cancer_Detector\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/liver+normal.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv(\"Dataset/liver+normal.csv\")\n",
    "df = shuffle(df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "display(df.head(5), df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.652082</td>\n",
       "      <td>5.829330</td>\n",
       "      <td>4.132451</td>\n",
       "      <td>6.030430</td>\n",
       "      <td>1.927296</td>\n",
       "      <td>6.580177</td>\n",
       "      <td>4.980347</td>\n",
       "      <td>3.076874</td>\n",
       "      <td>7.718815</td>\n",
       "      <td>2.746636</td>\n",
       "      <td>...</td>\n",
       "      <td>11.471340</td>\n",
       "      <td>11.092752</td>\n",
       "      <td>12.632323</td>\n",
       "      <td>12.748295</td>\n",
       "      <td>8.793452</td>\n",
       "      <td>7.316137</td>\n",
       "      <td>7.206730</td>\n",
       "      <td>1.760923</td>\n",
       "      <td>2.028388</td>\n",
       "      <td>2.211593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.423328</td>\n",
       "      <td>7.450621</td>\n",
       "      <td>9.333897</td>\n",
       "      <td>7.656993</td>\n",
       "      <td>2.911457</td>\n",
       "      <td>7.410254</td>\n",
       "      <td>5.000415</td>\n",
       "      <td>5.582219</td>\n",
       "      <td>4.886996</td>\n",
       "      <td>8.459350</td>\n",
       "      <td>...</td>\n",
       "      <td>11.740758</td>\n",
       "      <td>10.860109</td>\n",
       "      <td>13.503857</td>\n",
       "      <td>13.180561</td>\n",
       "      <td>3.346297</td>\n",
       "      <td>3.160720</td>\n",
       "      <td>2.810799</td>\n",
       "      <td>2.350106</td>\n",
       "      <td>3.004168</td>\n",
       "      <td>2.535307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.433211</td>\n",
       "      <td>7.145168</td>\n",
       "      <td>7.249280</td>\n",
       "      <td>7.694716</td>\n",
       "      <td>3.192009</td>\n",
       "      <td>8.595681</td>\n",
       "      <td>5.396035</td>\n",
       "      <td>7.898516</td>\n",
       "      <td>9.596738</td>\n",
       "      <td>4.069072</td>\n",
       "      <td>...</td>\n",
       "      <td>12.475954</td>\n",
       "      <td>11.520951</td>\n",
       "      <td>13.896514</td>\n",
       "      <td>13.616080</td>\n",
       "      <td>3.799339</td>\n",
       "      <td>3.790774</td>\n",
       "      <td>3.159305</td>\n",
       "      <td>2.970557</td>\n",
       "      <td>3.527868</td>\n",
       "      <td>3.195505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.022610</td>\n",
       "      <td>6.666889</td>\n",
       "      <td>6.822420</td>\n",
       "      <td>8.014927</td>\n",
       "      <td>3.529340</td>\n",
       "      <td>8.714623</td>\n",
       "      <td>5.759964</td>\n",
       "      <td>4.911467</td>\n",
       "      <td>6.880929</td>\n",
       "      <td>3.633933</td>\n",
       "      <td>...</td>\n",
       "      <td>12.778428</td>\n",
       "      <td>12.178552</td>\n",
       "      <td>13.903772</td>\n",
       "      <td>13.836587</td>\n",
       "      <td>9.775054</td>\n",
       "      <td>5.620937</td>\n",
       "      <td>7.650794</td>\n",
       "      <td>3.365332</td>\n",
       "      <td>3.695016</td>\n",
       "      <td>3.658442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.190901</td>\n",
       "      <td>6.591266</td>\n",
       "      <td>6.087219</td>\n",
       "      <td>7.647090</td>\n",
       "      <td>2.929891</td>\n",
       "      <td>7.258371</td>\n",
       "      <td>5.000119</td>\n",
       "      <td>4.869540</td>\n",
       "      <td>5.076104</td>\n",
       "      <td>11.863726</td>\n",
       "      <td>...</td>\n",
       "      <td>11.455975</td>\n",
       "      <td>10.532726</td>\n",
       "      <td>13.192335</td>\n",
       "      <td>12.715543</td>\n",
       "      <td>3.565291</td>\n",
       "      <td>3.211610</td>\n",
       "      <td>2.666262</td>\n",
       "      <td>2.482683</td>\n",
       "      <td>3.016364</td>\n",
       "      <td>2.746953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1007_s_at   1053_at    117_at    121_at  1255_g_at   1294_at   1316_at  \\\n",
       "0   8.652082  5.829330  4.132451  6.030430   1.927296  6.580177  4.980347   \n",
       "1   7.423328  7.450621  9.333897  7.656993   2.911457  7.410254  5.000415   \n",
       "2  10.433211  7.145168  7.249280  7.694716   3.192009  8.595681  5.396035   \n",
       "3  11.022610  6.666889  6.822420  8.014927   3.529340  8.714623  5.759964   \n",
       "4   7.190901  6.591266  6.087219  7.647090   2.929891  7.258371  5.000119   \n",
       "\n",
       "    1320_at  1405_i_at    1431_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n",
       "0  3.076874   7.718815   2.746636  ...             11.471340   \n",
       "1  5.582219   4.886996   8.459350  ...             11.740758   \n",
       "2  7.898516   9.596738   4.069072  ...             12.475954   \n",
       "3  4.911467   6.880929   3.633933  ...             12.778428   \n",
       "4  4.869540   5.076104  11.863726  ...             11.455975   \n",
       "\n",
       "   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "0             11.092752            12.632323            12.748295   \n",
       "1             10.860109            13.503857            13.180561   \n",
       "2             11.520951            13.896514            13.616080   \n",
       "3             12.178552            13.903772            13.836587   \n",
       "4             10.532726            13.192335            12.715543   \n",
       "\n",
       "   AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n",
       "0        8.793452        7.316137        7.206730         1.760923   \n",
       "1        3.346297        3.160720        2.810799         2.350106   \n",
       "2        3.799339        3.790774        3.159305         2.970557   \n",
       "3        9.775054        5.620937        7.650794         3.365332   \n",
       "4        3.565291        3.211610        2.666262         2.482683   \n",
       "\n",
       "   AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0         2.028388         2.211593  \n",
       "1         3.004168         2.535307  \n",
       "2         3.527868         3.195505  \n",
       "3         3.695016         3.658442  \n",
       "4         3.016364         2.746953  \n",
       "\n",
       "[5 rows x 54675 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(144, 54675)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: cancer_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(144,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    \n",
    "    # Drop type Columns\n",
    "    if \"type\" in df.columns:\n",
    "        df = df.drop(columns=\"type\")\n",
    "\n",
    "    # Convert label to binary type:\n",
    "    if 'cancer_type' in df.columns and not df['cancer_type'].isin([0, 1]).all():\n",
    "        df['cancer_type'] = df['cancer_type'].map({'liver': 1, 'normal': 0})\n",
    "    \n",
    "    # Get X,y\n",
    "    target = 'cancer_type'\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target]\n",
    "    \n",
    "    return X,y \n",
    "\n",
    "X,y = preprocessing(df)\n",
    "display(X.head(5), X.shape)\n",
    "display(y.head(5), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected features: 54675\n",
      "Selected features: Index(['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at', '1294_at',\n",
      "       '1316_at', '1320_at', '1405_i_at', '1431_at',\n",
      "       ...\n",
      "       'AFFX-r2-Ec-bioD-3_at', 'AFFX-r2-Ec-bioD-5_at', 'AFFX-r2-P1-cre-3_at',\n",
      "       'AFFX-r2-P1-cre-5_at', 'AFFX-ThrX-3_at', 'AFFX-ThrX-5_at',\n",
      "       'AFFX-ThrX-M_at', 'AFFX-TrpnX-3_at', 'AFFX-TrpnX-5_at',\n",
      "       'AFFX-TrpnX-M_at'],\n",
      "      dtype='object', length=54675)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Variance Threshold (Assume Features with higher variance => better)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0.01\n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "X_var = selector.fit_transform(X)\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "X_var = X.columns[selected_feature_indices]\n",
    "print(f\"Number of selected features: {len(X_var)}\")\n",
    "print(f\"Selected features: {X_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['1431_at', '1552307_a_at', '1552319_a_at', '1552362_a_at', '1552880_at',\n",
      "       '1553243_at', '1554420_at', '1554459_s_at', '1554491_a_at',\n",
      "       '1555345_at',\n",
      "       ...\n",
      "       '242329_at', '242720_at', '243618_s_at', '243799_x_at', '244650_at',\n",
      "       '31835_at', '34187_at', '37117_at', '39763_at', '49111_at'],\n",
      "      dtype='object', length=300)\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Unvariate feature selection method (Based on their relation with output)\n",
    "# ANOVA f-statistics\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select top 1000 features based on ANOVA F-statistic\n",
    "k_best_selector = SelectKBest(score_func=f_classif, k=300)\n",
    "X_anova = k_best_selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "X_anova = X.columns[k_best_selector.get_support()]\n",
    "\n",
    "print(f\"Selected features: {X_anova}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['1552362_a_at', '1552557_a_at', '1552797_s_at', '1552880_at',\n",
      "       '1553998_at', '1554220_a_at', '1554459_s_at', '1554491_a_at',\n",
      "       '1555695_a_at', '1556221_a_at',\n",
      "       ...\n",
      "       '244751_at', '34187_at', '39763_at', '43511_s_at', '49111_at',\n",
      "       '57588_at', 'AFFX-DapX-M_at', 'AFFX-LysX-5_at', 'AFFX-r2-Bs-thr-M_s_at',\n",
      "       'AFFX-ThrX-5_at'],\n",
      "      dtype='object', length=300)\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Mutual Information methnod (Non-linear relationship between predictors and targets)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Select top 100 features based on Mutual Information\n",
    "mutual_info_selector = SelectKBest(score_func=mutual_info_classif, k=300)\n",
    "X_mut = mutual_info_selector.fit_transform(X, y) \n",
    "\n",
    "# Get selected feature names\n",
    "X_mut = X.columns[mutual_info_selector.get_support()]\n",
    "\n",
    "print(f\"Selected features: {X_mut}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3  \n",
    "\n",
    "# Convert numpy arrays to flattened lists for compatibility\n",
    "variance_features = set(X_var.ravel())\n",
    "anova_features = set(X_anova.ravel())\n",
    "mutual_info_features = set(X_mut.ravel())\n",
    "\n",
    "# Create a Venn diagram to visualize the overlap\n",
    "plt.figure(figsize=(8, 6))\n",
    "venn_diagram = venn3(\n",
    "    subsets=(\n",
    "        len(variance_features - anova_features - mutual_info_features),  # Only Variance\n",
    "        len(anova_features - variance_features - mutual_info_features),  # Only ANOVA\n",
    "        len(variance_features & anova_features - mutual_info_features),  # Variance & ANOVA\n",
    "        len(mutual_info_features - variance_features - anova_features),  # Only Mutual Info\n",
    "        len(variance_features & mutual_info_features - anova_features),  # Variance & Mutual Info\n",
    "        len(anova_features & mutual_info_features - variance_features),  # ANOVA & Mutual Info\n",
    "        len(variance_features & anova_features & mutual_info_features),  # All 3 Methods\n",
    "    ),\n",
    "    set_labels=(\"Variance Threshold\", \"ANOVA\", \"Mutual Information\"),\n",
    ")\n",
    "plt.title(\"Feature Selection Overlap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>238388_x_at</th>\n",
       "      <th>217784_at</th>\n",
       "      <th>227672_at</th>\n",
       "      <th>1559663_at</th>\n",
       "      <th>202534_x_at</th>\n",
       "      <th>228405_at</th>\n",
       "      <th>224179_s_at</th>\n",
       "      <th>1552839_at</th>\n",
       "      <th>1570315_at</th>\n",
       "      <th>1556368_at</th>\n",
       "      <th>...</th>\n",
       "      <th>203305_at</th>\n",
       "      <th>218929_at</th>\n",
       "      <th>239899_at</th>\n",
       "      <th>240177_at</th>\n",
       "      <th>1566951_at</th>\n",
       "      <th>1558411_at</th>\n",
       "      <th>226235_at</th>\n",
       "      <th>216903_s_at</th>\n",
       "      <th>1554440_at</th>\n",
       "      <th>215454_x_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.029811</td>\n",
       "      <td>6.674299</td>\n",
       "      <td>6.363744</td>\n",
       "      <td>3.599104</td>\n",
       "      <td>5.111214</td>\n",
       "      <td>4.651466</td>\n",
       "      <td>3.689568</td>\n",
       "      <td>2.248077</td>\n",
       "      <td>4.110692</td>\n",
       "      <td>2.517728</td>\n",
       "      <td>...</td>\n",
       "      <td>6.585499</td>\n",
       "      <td>5.400750</td>\n",
       "      <td>2.576637</td>\n",
       "      <td>2.807573</td>\n",
       "      <td>2.233937</td>\n",
       "      <td>2.382939</td>\n",
       "      <td>6.490022</td>\n",
       "      <td>7.209933</td>\n",
       "      <td>2.488274</td>\n",
       "      <td>5.657036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.112054</td>\n",
       "      <td>7.008691</td>\n",
       "      <td>6.595200</td>\n",
       "      <td>3.442943</td>\n",
       "      <td>9.511106</td>\n",
       "      <td>5.806120</td>\n",
       "      <td>4.541473</td>\n",
       "      <td>3.234905</td>\n",
       "      <td>5.221262</td>\n",
       "      <td>3.395097</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556683</td>\n",
       "      <td>5.513349</td>\n",
       "      <td>2.812630</td>\n",
       "      <td>2.884821</td>\n",
       "      <td>3.322116</td>\n",
       "      <td>2.559554</td>\n",
       "      <td>7.944474</td>\n",
       "      <td>8.295001</td>\n",
       "      <td>2.808527</td>\n",
       "      <td>5.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.266095</td>\n",
       "      <td>7.550801</td>\n",
       "      <td>7.251719</td>\n",
       "      <td>3.852906</td>\n",
       "      <td>6.861011</td>\n",
       "      <td>5.913252</td>\n",
       "      <td>5.457879</td>\n",
       "      <td>3.220037</td>\n",
       "      <td>5.726334</td>\n",
       "      <td>4.105204</td>\n",
       "      <td>...</td>\n",
       "      <td>8.879121</td>\n",
       "      <td>7.608164</td>\n",
       "      <td>3.742258</td>\n",
       "      <td>3.657893</td>\n",
       "      <td>3.615659</td>\n",
       "      <td>4.081790</td>\n",
       "      <td>8.621846</td>\n",
       "      <td>9.113518</td>\n",
       "      <td>3.825052</td>\n",
       "      <td>12.395258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.135004</td>\n",
       "      <td>8.824154</td>\n",
       "      <td>7.585635</td>\n",
       "      <td>3.743313</td>\n",
       "      <td>9.242340</td>\n",
       "      <td>6.860689</td>\n",
       "      <td>4.726817</td>\n",
       "      <td>3.891107</td>\n",
       "      <td>5.711041</td>\n",
       "      <td>4.096657</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345335</td>\n",
       "      <td>8.586088</td>\n",
       "      <td>3.680203</td>\n",
       "      <td>4.243855</td>\n",
       "      <td>4.161171</td>\n",
       "      <td>3.122976</td>\n",
       "      <td>7.667858</td>\n",
       "      <td>9.009704</td>\n",
       "      <td>4.935529</td>\n",
       "      <td>6.593566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.687635</td>\n",
       "      <td>6.806639</td>\n",
       "      <td>6.572151</td>\n",
       "      <td>3.205625</td>\n",
       "      <td>9.069513</td>\n",
       "      <td>6.386390</td>\n",
       "      <td>4.894569</td>\n",
       "      <td>3.464237</td>\n",
       "      <td>5.580804</td>\n",
       "      <td>3.087809</td>\n",
       "      <td>...</td>\n",
       "      <td>6.477203</td>\n",
       "      <td>6.285154</td>\n",
       "      <td>3.360116</td>\n",
       "      <td>3.076190</td>\n",
       "      <td>3.571576</td>\n",
       "      <td>2.867347</td>\n",
       "      <td>7.605164</td>\n",
       "      <td>8.147059</td>\n",
       "      <td>3.036678</td>\n",
       "      <td>5.526937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   238388_x_at  217784_at  227672_at  1559663_at  202534_x_at  228405_at  \\\n",
       "0     5.029811   6.674299   6.363744    3.599104     5.111214   4.651466   \n",
       "1     5.112054   7.008691   6.595200    3.442943     9.511106   5.806120   \n",
       "2     6.266095   7.550801   7.251719    3.852906     6.861011   5.913252   \n",
       "3     6.135004   8.824154   7.585635    3.743313     9.242340   6.860689   \n",
       "4     5.687635   6.806639   6.572151    3.205625     9.069513   6.386390   \n",
       "\n",
       "   224179_s_at  1552839_at  1570315_at  1556368_at  ...  203305_at  218929_at  \\\n",
       "0     3.689568    2.248077    4.110692    2.517728  ...   6.585499   5.400750   \n",
       "1     4.541473    3.234905    5.221262    3.395097  ...   5.556683   5.513349   \n",
       "2     5.457879    3.220037    5.726334    4.105204  ...   8.879121   7.608164   \n",
       "3     4.726817    3.891107    5.711041    4.096657  ...   7.345335   8.586088   \n",
       "4     4.894569    3.464237    5.580804    3.087809  ...   6.477203   6.285154   \n",
       "\n",
       "   239899_at  240177_at  1566951_at  1558411_at  226235_at  216903_s_at  \\\n",
       "0   2.576637   2.807573    2.233937    2.382939   6.490022     7.209933   \n",
       "1   2.812630   2.884821    3.322116    2.559554   7.944474     8.295001   \n",
       "2   3.742258   3.657893    3.615659    4.081790   8.621846     9.113518   \n",
       "3   3.680203   4.243855    4.161171    3.122976   7.667858     9.009704   \n",
       "4   3.360116   3.076190    3.571576    2.867347   7.605164     8.147059   \n",
       "\n",
       "   1554440_at  215454_x_at  \n",
       "0    2.488274     5.657036  \n",
       "1    2.808527     5.246000  \n",
       "2    3.825052    12.395258  \n",
       "3    4.935529     6.593566  \n",
       "4    3.036678     5.526937  \n",
       "\n",
       "[5 rows x 54675 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Perform feature_selection (ANOVA, Mutual Information, Reduce Overlap)\n",
    "def feature_selection(X,y):\n",
    "    # Perform ANOVA\n",
    "    k_best_selector = SelectKBest(score_func=f_classif, k=300)\n",
    "    X_anova = k_best_selector.fit_transform(X,y)\n",
    "    X_anova = X.columns[k_best_selector.get_support()]\n",
    "    \n",
    "    # Perform Mutual Information\n",
    "    mutual_info_selector = SelectKBest(score_func=mutual_info_classif, k=300)\n",
    "    X_mut = mutual_info_selector.fit_transform(X,y)\n",
    "    X_mut = X.columns[mutual_info_selector.get_support()]\n",
    "    \n",
    "    # # Reduce overlap\n",
    "    # X_reduce = set(X_anova).difference(set(X_mut))\n",
    "    # X_reduce = X[list(X_reduce)]\n",
    "    \n",
    "    # X_reduce = X_anova.intersection(X_mut)  # Features in both ANOVA and Mutual Information\n",
    "    # X_reduce = X[list(X_reduce)]  # Subset of data with overlapping features\n",
    "    \n",
    "    combined_features = set(X_anova).union(set(X_mut)).union(set(X_var))\n",
    "    X_reduce = X[list(combined_features)]  # Subset the data to include combined features\n",
    "    \n",
    "    return X_reduce\n",
    "\n",
    "X = feature_selection(X,y)\n",
    "display(X.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>238388_x_at</th>\n",
       "      <th>217784_at</th>\n",
       "      <th>227672_at</th>\n",
       "      <th>1559663_at</th>\n",
       "      <th>202534_x_at</th>\n",
       "      <th>228405_at</th>\n",
       "      <th>224179_s_at</th>\n",
       "      <th>1552839_at</th>\n",
       "      <th>1570315_at</th>\n",
       "      <th>1556368_at</th>\n",
       "      <th>...</th>\n",
       "      <th>203305_at</th>\n",
       "      <th>218929_at</th>\n",
       "      <th>239899_at</th>\n",
       "      <th>240177_at</th>\n",
       "      <th>1566951_at</th>\n",
       "      <th>1558411_at</th>\n",
       "      <th>226235_at</th>\n",
       "      <th>216903_s_at</th>\n",
       "      <th>1554440_at</th>\n",
       "      <th>215454_x_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.029811</td>\n",
       "      <td>6.674299</td>\n",
       "      <td>6.363744</td>\n",
       "      <td>3.599104</td>\n",
       "      <td>5.111214</td>\n",
       "      <td>4.651466</td>\n",
       "      <td>3.689568</td>\n",
       "      <td>2.248077</td>\n",
       "      <td>4.110692</td>\n",
       "      <td>2.517728</td>\n",
       "      <td>...</td>\n",
       "      <td>6.585499</td>\n",
       "      <td>5.400750</td>\n",
       "      <td>2.576637</td>\n",
       "      <td>2.807573</td>\n",
       "      <td>2.233937</td>\n",
       "      <td>2.382939</td>\n",
       "      <td>6.490022</td>\n",
       "      <td>7.209933</td>\n",
       "      <td>2.488274</td>\n",
       "      <td>5.657036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.112054</td>\n",
       "      <td>7.008691</td>\n",
       "      <td>6.595200</td>\n",
       "      <td>3.442943</td>\n",
       "      <td>9.511106</td>\n",
       "      <td>5.806120</td>\n",
       "      <td>4.541473</td>\n",
       "      <td>3.234905</td>\n",
       "      <td>5.221262</td>\n",
       "      <td>3.395097</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556683</td>\n",
       "      <td>5.513349</td>\n",
       "      <td>2.812630</td>\n",
       "      <td>2.884821</td>\n",
       "      <td>3.322116</td>\n",
       "      <td>2.559554</td>\n",
       "      <td>7.944474</td>\n",
       "      <td>8.295001</td>\n",
       "      <td>2.808527</td>\n",
       "      <td>5.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.266095</td>\n",
       "      <td>7.550801</td>\n",
       "      <td>7.251719</td>\n",
       "      <td>3.852906</td>\n",
       "      <td>6.861011</td>\n",
       "      <td>5.913252</td>\n",
       "      <td>5.457879</td>\n",
       "      <td>3.220037</td>\n",
       "      <td>5.726334</td>\n",
       "      <td>4.105204</td>\n",
       "      <td>...</td>\n",
       "      <td>8.879121</td>\n",
       "      <td>7.608164</td>\n",
       "      <td>3.742258</td>\n",
       "      <td>3.657893</td>\n",
       "      <td>3.615659</td>\n",
       "      <td>4.081790</td>\n",
       "      <td>8.621846</td>\n",
       "      <td>9.113518</td>\n",
       "      <td>3.825052</td>\n",
       "      <td>12.395258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.135004</td>\n",
       "      <td>8.824154</td>\n",
       "      <td>7.585635</td>\n",
       "      <td>3.743313</td>\n",
       "      <td>9.242340</td>\n",
       "      <td>6.860689</td>\n",
       "      <td>4.726817</td>\n",
       "      <td>3.891107</td>\n",
       "      <td>5.711041</td>\n",
       "      <td>4.096657</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345335</td>\n",
       "      <td>8.586088</td>\n",
       "      <td>3.680203</td>\n",
       "      <td>4.243855</td>\n",
       "      <td>4.161171</td>\n",
       "      <td>3.122976</td>\n",
       "      <td>7.667858</td>\n",
       "      <td>9.009704</td>\n",
       "      <td>4.935529</td>\n",
       "      <td>6.593566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.687635</td>\n",
       "      <td>6.806639</td>\n",
       "      <td>6.572151</td>\n",
       "      <td>3.205625</td>\n",
       "      <td>9.069513</td>\n",
       "      <td>6.386390</td>\n",
       "      <td>4.894569</td>\n",
       "      <td>3.464237</td>\n",
       "      <td>5.580804</td>\n",
       "      <td>3.087809</td>\n",
       "      <td>...</td>\n",
       "      <td>6.477203</td>\n",
       "      <td>6.285154</td>\n",
       "      <td>3.360116</td>\n",
       "      <td>3.076190</td>\n",
       "      <td>3.571576</td>\n",
       "      <td>2.867347</td>\n",
       "      <td>7.605164</td>\n",
       "      <td>8.147059</td>\n",
       "      <td>3.036678</td>\n",
       "      <td>5.526937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5.800597</td>\n",
       "      <td>6.822442</td>\n",
       "      <td>7.130762</td>\n",
       "      <td>3.425058</td>\n",
       "      <td>8.473468</td>\n",
       "      <td>5.905895</td>\n",
       "      <td>5.058941</td>\n",
       "      <td>3.174386</td>\n",
       "      <td>5.292136</td>\n",
       "      <td>2.932354</td>\n",
       "      <td>...</td>\n",
       "      <td>5.541659</td>\n",
       "      <td>6.472994</td>\n",
       "      <td>3.275064</td>\n",
       "      <td>3.107851</td>\n",
       "      <td>3.392743</td>\n",
       "      <td>5.286377</td>\n",
       "      <td>7.855606</td>\n",
       "      <td>8.490637</td>\n",
       "      <td>2.838916</td>\n",
       "      <td>6.014850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.448654</td>\n",
       "      <td>8.816337</td>\n",
       "      <td>8.922971</td>\n",
       "      <td>4.566191</td>\n",
       "      <td>9.223569</td>\n",
       "      <td>8.328722</td>\n",
       "      <td>7.544974</td>\n",
       "      <td>6.166910</td>\n",
       "      <td>6.988882</td>\n",
       "      <td>5.906030</td>\n",
       "      <td>...</td>\n",
       "      <td>10.243942</td>\n",
       "      <td>8.127889</td>\n",
       "      <td>7.178143</td>\n",
       "      <td>5.229891</td>\n",
       "      <td>6.458987</td>\n",
       "      <td>4.796366</td>\n",
       "      <td>8.490557</td>\n",
       "      <td>10.045595</td>\n",
       "      <td>5.650110</td>\n",
       "      <td>7.256476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5.282412</td>\n",
       "      <td>7.188146</td>\n",
       "      <td>6.258815</td>\n",
       "      <td>4.745538</td>\n",
       "      <td>8.856930</td>\n",
       "      <td>5.786028</td>\n",
       "      <td>4.975722</td>\n",
       "      <td>3.134078</td>\n",
       "      <td>5.125790</td>\n",
       "      <td>2.985531</td>\n",
       "      <td>...</td>\n",
       "      <td>4.219019</td>\n",
       "      <td>6.403049</td>\n",
       "      <td>3.157548</td>\n",
       "      <td>2.786275</td>\n",
       "      <td>3.349358</td>\n",
       "      <td>2.979889</td>\n",
       "      <td>5.542369</td>\n",
       "      <td>8.982469</td>\n",
       "      <td>3.348267</td>\n",
       "      <td>5.287594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.655530</td>\n",
       "      <td>7.889048</td>\n",
       "      <td>7.604022</td>\n",
       "      <td>3.593613</td>\n",
       "      <td>7.950132</td>\n",
       "      <td>6.542679</td>\n",
       "      <td>4.668660</td>\n",
       "      <td>3.738049</td>\n",
       "      <td>5.533039</td>\n",
       "      <td>3.564837</td>\n",
       "      <td>...</td>\n",
       "      <td>6.398146</td>\n",
       "      <td>7.062915</td>\n",
       "      <td>3.889134</td>\n",
       "      <td>4.269071</td>\n",
       "      <td>4.220868</td>\n",
       "      <td>3.154637</td>\n",
       "      <td>8.313478</td>\n",
       "      <td>8.944499</td>\n",
       "      <td>3.807481</td>\n",
       "      <td>6.432389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.803773</td>\n",
       "      <td>7.996786</td>\n",
       "      <td>7.373297</td>\n",
       "      <td>3.629230</td>\n",
       "      <td>8.379146</td>\n",
       "      <td>7.027043</td>\n",
       "      <td>5.788300</td>\n",
       "      <td>3.992307</td>\n",
       "      <td>6.425195</td>\n",
       "      <td>4.018604</td>\n",
       "      <td>...</td>\n",
       "      <td>9.676873</td>\n",
       "      <td>7.937300</td>\n",
       "      <td>4.684581</td>\n",
       "      <td>4.293261</td>\n",
       "      <td>4.521677</td>\n",
       "      <td>3.795177</td>\n",
       "      <td>8.988282</td>\n",
       "      <td>9.480845</td>\n",
       "      <td>4.420063</td>\n",
       "      <td>12.668590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 54675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     238388_x_at  217784_at  227672_at  1559663_at  202534_x_at  228405_at  \\\n",
       "0       5.029811   6.674299   6.363744    3.599104     5.111214   4.651466   \n",
       "1       5.112054   7.008691   6.595200    3.442943     9.511106   5.806120   \n",
       "2       6.266095   7.550801   7.251719    3.852906     6.861011   5.913252   \n",
       "3       6.135004   8.824154   7.585635    3.743313     9.242340   6.860689   \n",
       "4       5.687635   6.806639   6.572151    3.205625     9.069513   6.386390   \n",
       "..           ...        ...        ...         ...          ...        ...   \n",
       "139     5.800597   6.822442   7.130762    3.425058     8.473468   5.905895   \n",
       "140     7.448654   8.816337   8.922971    4.566191     9.223569   8.328722   \n",
       "141     5.282412   7.188146   6.258815    4.745538     8.856930   5.786028   \n",
       "142     5.655530   7.889048   7.604022    3.593613     7.950132   6.542679   \n",
       "143     6.803773   7.996786   7.373297    3.629230     8.379146   7.027043   \n",
       "\n",
       "     224179_s_at  1552839_at  1570315_at  1556368_at  ...  203305_at  \\\n",
       "0       3.689568    2.248077    4.110692    2.517728  ...   6.585499   \n",
       "1       4.541473    3.234905    5.221262    3.395097  ...   5.556683   \n",
       "2       5.457879    3.220037    5.726334    4.105204  ...   8.879121   \n",
       "3       4.726817    3.891107    5.711041    4.096657  ...   7.345335   \n",
       "4       4.894569    3.464237    5.580804    3.087809  ...   6.477203   \n",
       "..           ...         ...         ...         ...  ...        ...   \n",
       "139     5.058941    3.174386    5.292136    2.932354  ...   5.541659   \n",
       "140     7.544974    6.166910    6.988882    5.906030  ...  10.243942   \n",
       "141     4.975722    3.134078    5.125790    2.985531  ...   4.219019   \n",
       "142     4.668660    3.738049    5.533039    3.564837  ...   6.398146   \n",
       "143     5.788300    3.992307    6.425195    4.018604  ...   9.676873   \n",
       "\n",
       "     218929_at  239899_at  240177_at  1566951_at  1558411_at  226235_at  \\\n",
       "0     5.400750   2.576637   2.807573    2.233937    2.382939   6.490022   \n",
       "1     5.513349   2.812630   2.884821    3.322116    2.559554   7.944474   \n",
       "2     7.608164   3.742258   3.657893    3.615659    4.081790   8.621846   \n",
       "3     8.586088   3.680203   4.243855    4.161171    3.122976   7.667858   \n",
       "4     6.285154   3.360116   3.076190    3.571576    2.867347   7.605164   \n",
       "..         ...        ...        ...         ...         ...        ...   \n",
       "139   6.472994   3.275064   3.107851    3.392743    5.286377   7.855606   \n",
       "140   8.127889   7.178143   5.229891    6.458987    4.796366   8.490557   \n",
       "141   6.403049   3.157548   2.786275    3.349358    2.979889   5.542369   \n",
       "142   7.062915   3.889134   4.269071    4.220868    3.154637   8.313478   \n",
       "143   7.937300   4.684581   4.293261    4.521677    3.795177   8.988282   \n",
       "\n",
       "     216903_s_at  1554440_at  215454_x_at  \n",
       "0       7.209933    2.488274     5.657036  \n",
       "1       8.295001    2.808527     5.246000  \n",
       "2       9.113518    3.825052    12.395258  \n",
       "3       9.009704    4.935529     6.593566  \n",
       "4       8.147059    3.036678     5.526937  \n",
       "..           ...         ...          ...  \n",
       "139     8.490637    2.838916     6.014850  \n",
       "140    10.045595    5.650110     7.256476  \n",
       "141     8.982469    3.348267     5.287594  \n",
       "142     8.944499    3.807481     6.432389  \n",
       "143     9.480845    4.420063    12.668590  \n",
       "\n",
       "[144 rows x 54675 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "139    1\n",
       "140    0\n",
       "141    1\n",
       "142    0\n",
       "143    0\n",
       "Name: cancer_type, Length: 144, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Results:\n",
      "  Accuracy: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROC AUC: 1.0000\n",
      "------------------------------\n",
      "Fold 2 Results:\n",
      "  Accuracy: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROC AUC: 1.0000\n",
      "------------------------------\n",
      "Fold 3 Results:\n",
      "  Accuracy: 0.9655\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.9677\n",
      "  ROC AUC: 0.9762\n",
      "------------------------------\n",
      "Fold 4 Results:\n",
      "  Accuracy: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROC AUC: 1.0000\n",
      "------------------------------\n",
      "Fold 5 Results:\n",
      "  Accuracy: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROC AUC: 1.0000\n",
      "------------------------------\n",
      "\n",
      "Cross-Validation Summary:\n",
      "Mean Accuracy: 0.9931\n",
      "Mean Recall: 1.0000\n",
      "Mean F1 Score: 0.9935\n",
      "Mean ROC AUC: 0.9952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define Training Pipeline with Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Adjust n_estimators as needed\n",
    "])\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    # Append scores\n",
    "    accuracy_scores.append(accuracy)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # Print results for the current fold\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Final summary of metrics\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "print(f\"Mean ROC AUC: {np.mean(roc_auc_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>238388_x_at</th>\n",
       "      <th>217784_at</th>\n",
       "      <th>227672_at</th>\n",
       "      <th>1559663_at</th>\n",
       "      <th>202534_x_at</th>\n",
       "      <th>228405_at</th>\n",
       "      <th>224179_s_at</th>\n",
       "      <th>1552839_at</th>\n",
       "      <th>1570315_at</th>\n",
       "      <th>1556368_at</th>\n",
       "      <th>...</th>\n",
       "      <th>203305_at</th>\n",
       "      <th>218929_at</th>\n",
       "      <th>239899_at</th>\n",
       "      <th>240177_at</th>\n",
       "      <th>1566951_at</th>\n",
       "      <th>1558411_at</th>\n",
       "      <th>226235_at</th>\n",
       "      <th>216903_s_at</th>\n",
       "      <th>1554440_at</th>\n",
       "      <th>215454_x_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.783650</td>\n",
       "      <td>9.023616</td>\n",
       "      <td>7.904564</td>\n",
       "      <td>3.994269</td>\n",
       "      <td>8.826429</td>\n",
       "      <td>8.152477</td>\n",
       "      <td>6.792753</td>\n",
       "      <td>4.202891</td>\n",
       "      <td>6.343654</td>\n",
       "      <td>4.801736</td>\n",
       "      <td>...</td>\n",
       "      <td>7.764687</td>\n",
       "      <td>8.909022</td>\n",
       "      <td>5.372430</td>\n",
       "      <td>5.787134</td>\n",
       "      <td>5.977201</td>\n",
       "      <td>5.503237</td>\n",
       "      <td>8.990135</td>\n",
       "      <td>10.371105</td>\n",
       "      <td>4.947385</td>\n",
       "      <td>7.592880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.608440</td>\n",
       "      <td>8.779251</td>\n",
       "      <td>8.691766</td>\n",
       "      <td>3.964347</td>\n",
       "      <td>8.550942</td>\n",
       "      <td>7.698653</td>\n",
       "      <td>6.434160</td>\n",
       "      <td>4.427659</td>\n",
       "      <td>6.732863</td>\n",
       "      <td>5.923386</td>\n",
       "      <td>...</td>\n",
       "      <td>8.440360</td>\n",
       "      <td>9.393714</td>\n",
       "      <td>5.217811</td>\n",
       "      <td>5.353448</td>\n",
       "      <td>5.568108</td>\n",
       "      <td>5.600619</td>\n",
       "      <td>8.841113</td>\n",
       "      <td>11.007056</td>\n",
       "      <td>4.966936</td>\n",
       "      <td>7.219633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.809472</td>\n",
       "      <td>5.745000</td>\n",
       "      <td>7.519824</td>\n",
       "      <td>2.706544</td>\n",
       "      <td>6.397554</td>\n",
       "      <td>6.614698</td>\n",
       "      <td>3.873674</td>\n",
       "      <td>3.932758</td>\n",
       "      <td>3.805982</td>\n",
       "      <td>3.580576</td>\n",
       "      <td>...</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>4.290323</td>\n",
       "      <td>4.049691</td>\n",
       "      <td>3.169894</td>\n",
       "      <td>3.506833</td>\n",
       "      <td>2.825557</td>\n",
       "      <td>5.860473</td>\n",
       "      <td>6.274160</td>\n",
       "      <td>3.255133</td>\n",
       "      <td>5.569304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.644442</td>\n",
       "      <td>6.316259</td>\n",
       "      <td>6.369184</td>\n",
       "      <td>3.146340</td>\n",
       "      <td>7.485904</td>\n",
       "      <td>5.553823</td>\n",
       "      <td>3.733413</td>\n",
       "      <td>3.320296</td>\n",
       "      <td>3.939057</td>\n",
       "      <td>2.692369</td>\n",
       "      <td>...</td>\n",
       "      <td>8.794493</td>\n",
       "      <td>5.767919</td>\n",
       "      <td>3.432874</td>\n",
       "      <td>2.695096</td>\n",
       "      <td>3.356033</td>\n",
       "      <td>2.568766</td>\n",
       "      <td>7.198218</td>\n",
       "      <td>7.005274</td>\n",
       "      <td>2.723599</td>\n",
       "      <td>5.300738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.903699</td>\n",
       "      <td>8.919435</td>\n",
       "      <td>7.472692</td>\n",
       "      <td>3.591190</td>\n",
       "      <td>8.269973</td>\n",
       "      <td>6.772539</td>\n",
       "      <td>5.023822</td>\n",
       "      <td>3.728736</td>\n",
       "      <td>5.605676</td>\n",
       "      <td>3.944457</td>\n",
       "      <td>...</td>\n",
       "      <td>5.723309</td>\n",
       "      <td>7.426341</td>\n",
       "      <td>3.834621</td>\n",
       "      <td>4.017338</td>\n",
       "      <td>3.846006</td>\n",
       "      <td>3.193040</td>\n",
       "      <td>7.827385</td>\n",
       "      <td>8.858052</td>\n",
       "      <td>4.795616</td>\n",
       "      <td>7.011299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.925524</td>\n",
       "      <td>9.846791</td>\n",
       "      <td>10.264731</td>\n",
       "      <td>4.518726</td>\n",
       "      <td>8.900640</td>\n",
       "      <td>7.878189</td>\n",
       "      <td>7.450108</td>\n",
       "      <td>5.784950</td>\n",
       "      <td>6.857211</td>\n",
       "      <td>5.644695</td>\n",
       "      <td>...</td>\n",
       "      <td>10.395874</td>\n",
       "      <td>9.587489</td>\n",
       "      <td>6.456591</td>\n",
       "      <td>4.888935</td>\n",
       "      <td>6.057431</td>\n",
       "      <td>4.305391</td>\n",
       "      <td>8.194533</td>\n",
       "      <td>9.585923</td>\n",
       "      <td>5.499569</td>\n",
       "      <td>7.234978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7.154945</td>\n",
       "      <td>8.388751</td>\n",
       "      <td>8.463063</td>\n",
       "      <td>4.453763</td>\n",
       "      <td>9.283655</td>\n",
       "      <td>7.596242</td>\n",
       "      <td>7.389516</td>\n",
       "      <td>6.306188</td>\n",
       "      <td>6.729398</td>\n",
       "      <td>5.155313</td>\n",
       "      <td>...</td>\n",
       "      <td>10.060576</td>\n",
       "      <td>8.510704</td>\n",
       "      <td>6.920534</td>\n",
       "      <td>4.715714</td>\n",
       "      <td>5.715172</td>\n",
       "      <td>4.373546</td>\n",
       "      <td>9.105160</td>\n",
       "      <td>10.053956</td>\n",
       "      <td>5.439777</td>\n",
       "      <td>7.032217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.116259</td>\n",
       "      <td>4.551351</td>\n",
       "      <td>7.574633</td>\n",
       "      <td>3.027083</td>\n",
       "      <td>6.734575</td>\n",
       "      <td>4.006833</td>\n",
       "      <td>4.106737</td>\n",
       "      <td>3.566409</td>\n",
       "      <td>4.834363</td>\n",
       "      <td>3.387022</td>\n",
       "      <td>...</td>\n",
       "      <td>4.857954</td>\n",
       "      <td>3.593543</td>\n",
       "      <td>4.052116</td>\n",
       "      <td>2.691217</td>\n",
       "      <td>3.366034</td>\n",
       "      <td>2.812785</td>\n",
       "      <td>3.302344</td>\n",
       "      <td>5.321943</td>\n",
       "      <td>2.877070</td>\n",
       "      <td>5.960251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6.431163</td>\n",
       "      <td>4.560012</td>\n",
       "      <td>7.565877</td>\n",
       "      <td>2.578221</td>\n",
       "      <td>6.028126</td>\n",
       "      <td>4.740745</td>\n",
       "      <td>3.487017</td>\n",
       "      <td>3.951009</td>\n",
       "      <td>5.192076</td>\n",
       "      <td>3.283562</td>\n",
       "      <td>...</td>\n",
       "      <td>4.915723</td>\n",
       "      <td>3.285554</td>\n",
       "      <td>4.087242</td>\n",
       "      <td>2.525919</td>\n",
       "      <td>3.401601</td>\n",
       "      <td>2.939114</td>\n",
       "      <td>3.221678</td>\n",
       "      <td>5.194967</td>\n",
       "      <td>3.343935</td>\n",
       "      <td>6.067356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.292547</td>\n",
       "      <td>4.616639</td>\n",
       "      <td>6.958630</td>\n",
       "      <td>2.988998</td>\n",
       "      <td>4.952033</td>\n",
       "      <td>3.581511</td>\n",
       "      <td>3.209783</td>\n",
       "      <td>3.323666</td>\n",
       "      <td>5.013482</td>\n",
       "      <td>3.319285</td>\n",
       "      <td>...</td>\n",
       "      <td>4.330335</td>\n",
       "      <td>3.478184</td>\n",
       "      <td>3.925324</td>\n",
       "      <td>2.584876</td>\n",
       "      <td>3.361404</td>\n",
       "      <td>3.299132</td>\n",
       "      <td>2.799761</td>\n",
       "      <td>5.451124</td>\n",
       "      <td>2.842452</td>\n",
       "      <td>5.397252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 54675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    238388_x_at  217784_at  227672_at  1559663_at  202534_x_at  228405_at  \\\n",
       "0      7.783650   9.023616   7.904564    3.994269     8.826429   8.152477   \n",
       "1      7.608440   8.779251   8.691766    3.964347     8.550942   7.698653   \n",
       "2      5.809472   5.745000   7.519824    2.706544     6.397554   6.614698   \n",
       "3      5.644442   6.316259   6.369184    3.146340     7.485904   5.553823   \n",
       "4      5.903699   8.919435   7.472692    3.591190     8.269973   6.772539   \n",
       "..          ...        ...        ...         ...          ...        ...   \n",
       "56     6.925524   9.846791  10.264731    4.518726     8.900640   7.878189   \n",
       "57     7.154945   8.388751   8.463063    4.453763     9.283655   7.596242   \n",
       "58     6.116259   4.551351   7.574633    3.027083     6.734575   4.006833   \n",
       "59     6.431163   4.560012   7.565877    2.578221     6.028126   4.740745   \n",
       "60     5.292547   4.616639   6.958630    2.988998     4.952033   3.581511   \n",
       "\n",
       "    224179_s_at  1552839_at  1570315_at  1556368_at  ...  203305_at  \\\n",
       "0      6.792753    4.202891    6.343654    4.801736  ...   7.764687   \n",
       "1      6.434160    4.427659    6.732863    5.923386  ...   8.440360   \n",
       "2      3.873674    3.932758    3.805982    3.580576  ...   6.875061   \n",
       "3      3.733413    3.320296    3.939057    2.692369  ...   8.794493   \n",
       "4      5.023822    3.728736    5.605676    3.944457  ...   5.723309   \n",
       "..          ...         ...         ...         ...  ...        ...   \n",
       "56     7.450108    5.784950    6.857211    5.644695  ...  10.395874   \n",
       "57     7.389516    6.306188    6.729398    5.155313  ...  10.060576   \n",
       "58     4.106737    3.566409    4.834363    3.387022  ...   4.857954   \n",
       "59     3.487017    3.951009    5.192076    3.283562  ...   4.915723   \n",
       "60     3.209783    3.323666    5.013482    3.319285  ...   4.330335   \n",
       "\n",
       "    218929_at  239899_at  240177_at  1566951_at  1558411_at  226235_at  \\\n",
       "0    8.909022   5.372430   5.787134    5.977201    5.503237   8.990135   \n",
       "1    9.393714   5.217811   5.353448    5.568108    5.600619   8.841113   \n",
       "2    4.290323   4.049691   3.169894    3.506833    2.825557   5.860473   \n",
       "3    5.767919   3.432874   2.695096    3.356033    2.568766   7.198218   \n",
       "4    7.426341   3.834621   4.017338    3.846006    3.193040   7.827385   \n",
       "..        ...        ...        ...         ...         ...        ...   \n",
       "56   9.587489   6.456591   4.888935    6.057431    4.305391   8.194533   \n",
       "57   8.510704   6.920534   4.715714    5.715172    4.373546   9.105160   \n",
       "58   3.593543   4.052116   2.691217    3.366034    2.812785   3.302344   \n",
       "59   3.285554   4.087242   2.525919    3.401601    2.939114   3.221678   \n",
       "60   3.478184   3.925324   2.584876    3.361404    3.299132   2.799761   \n",
       "\n",
       "    216903_s_at  1554440_at  215454_x_at  \n",
       "0     10.371105    4.947385     7.592880  \n",
       "1     11.007056    4.966936     7.219633  \n",
       "2      6.274160    3.255133     5.569304  \n",
       "3      7.005274    2.723599     5.300738  \n",
       "4      8.858052    4.795616     7.011299  \n",
       "..          ...         ...          ...  \n",
       "56     9.585923    5.499569     7.234978  \n",
       "57    10.053956    5.439777     7.032217  \n",
       "58     5.321943    2.877070     5.960251  \n",
       "59     5.194967    3.343935     6.067356  \n",
       "60     5.451124    2.842452     5.397252  \n",
       "\n",
       "[61 rows x 54675 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Name: cancer_type, Length: 61, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load and shuffle the dataset\n",
    "test_liver = pd.read_csv(\"Dataset/liver_test_data.csv\")\n",
    "X_test, y_test = preprocessing(test_liver)\n",
    "X_test = X_test[X.columns]\n",
    "display(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation on Test Dataset:\n",
      "Accuracy: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "ROC-AUC: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        52\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        61\n",
      "   macro avg       1.00      1.00      1.00        61\n",
      "weighted avg       1.00      1.00      1.00        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict using the final trained model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal Model Evaluation on Test Dataset:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction report saved to Dataset/test_set_prediction_report.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the report dataframe\n",
    "report_df = pd.DataFrame({\n",
    "    'True Label': y_test,\n",
    "    'Predicted Label': y_pred,\n",
    "    'Probability (Liver)': y_pred_prob\n",
    "})\n",
    "\n",
    "# Save the report to the Dataset directory\n",
    "output_path = \"Dataset/test_set_prediction_report.csv\"\n",
    "report_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Prediction report saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 16: Predicted Probability (Cancer - Class 1): 0.9400\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.260909\n",
      "4557   206916_x_at      0.247221\n",
      "40915  206651_s_at      0.240023\n",
      "13004    210215_at      0.224232\n",
      "35070  211298_s_at      0.134712\n",
      "6390   203400_s_at      0.132722\n",
      "15134  219466_s_at      0.127384\n",
      "10382  205649_s_at      0.126513\n",
      "37528  205041_s_at      0.124181\n",
      "33892    207218_at      0.120506\n",
      "\n",
      "Sample 17: Predicted Probability (Cancer - Class 1): 0.8900\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.255897\n",
      "40915  206651_s_at      0.244601\n",
      "4557   206916_x_at      0.227500\n",
      "13004    210215_at      0.222653\n",
      "35070  211298_s_at      0.133450\n",
      "6390   203400_s_at      0.130444\n",
      "15134  219466_s_at      0.129778\n",
      "37528  205041_s_at      0.122338\n",
      "10382  205649_s_at      0.121891\n",
      "35561    204988_at      0.118828\n",
      "\n",
      "Sample 18: Predicted Probability (Cancer - Class 1): 0.9800\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.250033\n",
      "40915  206651_s_at      0.241633\n",
      "13004    210215_at      0.230124\n",
      "4557   206916_x_at      0.182696\n",
      "35070  211298_s_at      0.135105\n",
      "15134  219466_s_at      0.128811\n",
      "6390   203400_s_at      0.127038\n",
      "10382  205649_s_at      0.125582\n",
      "37528  205041_s_at      0.121586\n",
      "35561    204988_at      0.118490\n",
      "\n",
      "Sample 19: Predicted Probability (Cancer - Class 1): 0.8900\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.255201\n",
      "40915  206651_s_at      0.243485\n",
      "4557   206916_x_at      0.236597\n",
      "13004    210215_at      0.231133\n",
      "35070  211298_s_at      0.136656\n",
      "6390   203400_s_at      0.129621\n",
      "15134  219466_s_at      0.128449\n",
      "10382  205649_s_at      0.127789\n",
      "37528  205041_s_at      0.124600\n",
      "33892    207218_at      0.120626\n",
      "\n",
      "Sample 20: Predicted Probability (Cancer - Class 1): 0.9600\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.261834\n",
      "40915  206651_s_at      0.247040\n",
      "13004    210215_at      0.235696\n",
      "4557   206916_x_at      0.220491\n",
      "35070  211298_s_at      0.135399\n",
      "6390   203400_s_at      0.132416\n",
      "15134  219466_s_at      0.130028\n",
      "37528  205041_s_at      0.120507\n",
      "10382  205649_s_at      0.116096\n",
      "35561    204988_at      0.114552\n",
      "\n",
      "Sample 21: Predicted Probability (Cancer - Class 1): 0.9200\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.258883\n",
      "40915  206651_s_at      0.233559\n",
      "13004    210215_at      0.222152\n",
      "4557   206916_x_at      0.184060\n",
      "35070  211298_s_at      0.135298\n",
      "6390   203400_s_at      0.129260\n",
      "15134  219466_s_at      0.128939\n",
      "10382  205649_s_at      0.126692\n",
      "35561    204988_at      0.119732\n",
      "37528  205041_s_at      0.118171\n",
      "\n",
      "Sample 22: Predicted Probability (Cancer - Class 1): 0.9400\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.257894\n",
      "40915  206651_s_at      0.240601\n",
      "13004    210215_at      0.223604\n",
      "4557   206916_x_at      0.194929\n",
      "35070  211298_s_at      0.136563\n",
      "6390   203400_s_at      0.133814\n",
      "15134  219466_s_at      0.128007\n",
      "10382  205649_s_at      0.124569\n",
      "37528  205041_s_at      0.122578\n",
      "35561    204988_at      0.120465\n",
      "\n",
      "Sample 23: Predicted Probability (Cancer - Class 1): 0.9100\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.249230\n",
      "40915  206651_s_at      0.239869\n",
      "4557   206916_x_at      0.228845\n",
      "13004    210215_at      0.217631\n",
      "35070  211298_s_at      0.136291\n",
      "6390   203400_s_at      0.130083\n",
      "15134  219466_s_at      0.128972\n",
      "10382  205649_s_at      0.127686\n",
      "37528  205041_s_at      0.124593\n",
      "35561    204988_at      0.121450\n",
      "\n",
      "Sample 24: Predicted Probability (Cancer - Class 1): 0.9300\n",
      "Top Contributing Features for This Sample:\n",
      "           Feature  Contribution\n",
      "21770  204561_x_at      0.263846\n",
      "40915  206651_s_at      0.246472\n",
      "13004    210215_at      0.232401\n",
      "4557   206916_x_at      0.218365\n",
      "6390   203400_s_at      0.136599\n",
      "35070  211298_s_at      0.135525\n",
      "15134  219466_s_at      0.129037\n",
      "33892    207218_at      0.125420\n",
      "37528  205041_s_at      0.124101\n",
      "10382  205649_s_at      0.120839\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Predict probabilities for the test dataset\n",
    "y_pred = pipeline.predict(X_test)  # Predicted class (0 or 1)\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:, 1]  # Probability for class 1\n",
    "\n",
    "# Extract feature importances from RandomForestClassifier\n",
    "feature_importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Loop through samples predicted as cancer (y = 1)\n",
    "for i, (pred, prob) in enumerate(zip(y_pred, y_pred_prob)):\n",
    "    if pred == 1:  # Only consider predictions for class 1 (cancer)\n",
    "        sample_features = X_test.iloc[i, :]  # Feature values for the sample\n",
    "        contributions = sample_features.values * feature_importances  # Calculate scaled contributions\n",
    "        \n",
    "        # Create a DataFrame for contributions\n",
    "        contribution_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Contribution': contributions\n",
    "        }).sort_values(by='Contribution', ascending=False)  # Sort by contribution\n",
    "        \n",
    "        # Print details for the sample\n",
    "        print(f\"\\nSample {i}: Predicted Probability (Cancer - Class 1): {prob:.4f}\")\n",
    "        print(\"Top Contributing Features for This Sample:\")\n",
    "        print(contribution_df.head(10))  # Display top 10 contributing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['liver.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'liver.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
